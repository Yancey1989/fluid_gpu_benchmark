apiVersion: batch/v1
kind: Job
metadata:
  name: vgg16-gpu-trainer
spec:
  parallelism: 4
  completions: 4
  template:
    metadata:
      labels:
        paddle-job: vgg16-gpu
    spec:
      imagePullSecrets:
        - name: job-registry-secret
      hostNetwork: true
      volumes:
        - name: nvidia-driver
          hostPath:
            path: /usr/local/nvidia/lib64
      containers:
      - name: trainer
        #image: "registry.baidu.com/paddlepaddle/fluid_benchmark:vgg16"
        image: "bootstrapper:5000/fluid_benchmark:vgg16"
        imagePullPolicy: Always
        command: ["paddle_k8s", "start_fluid"]
        #command: ["sleep", "3600"]
        #securityContext:
        #  privileged: true
        volumeMounts:
          - mountPath: /usr/local/nvidia/lib64
            name: nvidia-driver
        env:
        - name: PADDLE_JOB_NAME
          value: vgg16-gpu
        - name: TRAINING_ROLE
          value: "TRAINER"
        - name: TRAINERS
          value: "4"
        - name: PSERVERS
          value: "4"
        - name: TOPOLOGY
          value: ""
        #- name: GLOG_v
        #  value: "3"
        - name: FLAGS_fraction_of_gpu_memory_to_use
          value: "0.4"
        - name: FLAGS_benchmark
          value: "1"
        - name: GLOG_logtostderr
          value: "1"
        - name: MKL_NUM_THREADS
          value: "1"
        - name: ENTRY
          value: "unset http_proxy && unset https_proxy && python /workspace/vgg16_fluid.py --local 0 --batch_size 20 --data_set flowers --device GPU --device_id 0"
        - name: TRAINER_PACKAGE
          value: "/workspace"
        - name: PADDLE_INIT_PORT
          value: "30256"
        - name: PADDLE_INIT_NICS
          value: "eth2"
        - name: PADDLE_INIT_TRAINER_COUNT
          value: "1"
        - name: PADDLE_INIT_PORTS_NUM
          value: "1"
        - name: PADDLE_INIT_PORTS_NUM_FOR_SPARSE
          value: "1"
        - name: PADDLE_INIT_NUM_GRADIENT_SERVERS
          value: "4"
        - name: LD_LIBRARY_PATH
          value: "/usr/local/nvidia/lib64:/usr/local/lib:/usr/local/cuda/lib64"
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: "metadata.namespace"
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: "status.podIP"
        resources:
          requests:
            memory: 30Gi
            cpu: 2
            alpha.kubernetes.io/nvidia-gpu: 1
          limits:
            memory: 30Gi
            cpu: 2
            alpha.kubernetes.io/nvidia-gpu: 1
      restartPolicy: Never
